{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":2097406,"sourceType":"datasetVersion","datasetId":1257880},{"sourceId":10732704,"sourceType":"datasetVersion","datasetId":6654404},{"sourceId":247023,"sourceType":"modelInstanceVersion","modelInstanceId":211104,"modelId":232802}],"dockerImageVersionId":30763,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Knee X-ray Analysis Using ResNet for Osteoarthritis Severity Assessment","metadata":{}},{"cell_type":"markdown","source":"#  miRNA processing ","metadata":{}},{"cell_type":"code","source":"!pip install -q imbalanced-learn\n!pip install -q openpyxl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:37:20.111298Z","iopub.execute_input":"2025-02-12T14:37:20.111642Z","iopub.status.idle":"2025-02-12T14:37:27.10413Z","shell.execute_reply.started":"2025-02-12T14:37:20.111614Z","shell.execute_reply":"2025-02-12T14:37:27.102949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n# Step 1: Import Libraries (Kaggle already has imbalanced-learn, no need to install)\nfrom imblearn.over_sampling import SMOTE\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n\n# Step 2: Load Dataset\n# Check available files in dataset\nprint(\"Files in dataset directory:\", os.listdir(\"/kaggle/input/mirna-dataset\"))\n\n# Update the file name based on the dataset\nfile_path = \"/kaggle/input/mirna-dataset/mRNA.xlsx\"  # Replace with the actual filename\ndata = pd.read_excel(file_path)\n\n# Step 3: Preprocess Dataset\ndata_transposed = data.set_index('miRNA').T\ndata_transposed.reset_index(inplace=True)\n\n# Add mock 'Progression_Status' (binary: 0 = non-progressor, 1 = progressor) for demonstration\ndata_transposed['Progression_Status'] = np.random.choice([0, 1], size=len(data_transposed))\n\n# Select relevant features (excluding 'Age')\nselected_features = ['hsa-miR-556-3p', 'hsa-miR-3157-5p', 'hsa-miR-200a-5p', 'hsa-miR-141-3p']\ntarget = 'Progression_Status'\n\n# Filter dataset\nfiltered_data = data_transposed[selected_features + [target]].dropna()\n\nX = filtered_data[selected_features]\ny = filtered_data[target]\n\n# Step 4: Handle Class Imbalance with SMOTE\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Step 5: Hyperparameter Tuning with GridSearchCV\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'class_weight': [None, 'balanced', 'balanced_subsample']\n}\n\nrf_model = RandomForestClassifier(random_state=42)\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ngrid_search = GridSearchCV(rf_model, param_grid, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=2)\ngrid_search.fit(X_resampled, y_resampled)\n\n# Step 6: Evaluate the Best Model\nbest_model = grid_search.best_estimator_\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n\ny_pred = best_model.predict(X_test)\ny_prob = best_model.predict_proba(X_test)[:, 1]\n\naccuracy = accuracy_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_prob)\n\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(f\"Improved Accuracy: {accuracy:.2f}\")\nprint(f\"Improved AUC: {auc:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Step 7: Visualize Feature Importance\nfeature_importances = best_model.feature_importances_\nplt.barh(selected_features, feature_importances)\nplt.xlabel('Feature Importance')\nplt.title('Improved Random Forest Feature Importance')\n\n# Save Feature Importance Plot\nfeature_importance_path = \"/kaggle/working/feature_importance.png\"\nplt.savefig(feature_importance_path)\nplt.show()\nprint(f\"Feature importance plot saved at: {feature_importance_path}\")\n\n# Step 8: Save miRNA Model Predictions\nmiRNA_probs = best_model.predict_proba(X)[:, 1]  # Probability of class 1\nmiRNA_pred_df = pd.DataFrame({'miRNA_pred': miRNA_probs})\n\n# Save predictions to CSV\ncsv_path = \"/kaggle/working/miRNA_predictions.csv\"\nmiRNA_pred_df.to_csv(csv_path, index=False)\n\nprint(f\"miRNA predictions saved successfully at {csv_path}!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:37:27.106165Z","iopub.execute_input":"2025-02-12T14:37:27.106454Z","iopub.status.idle":"2025-02-12T14:37:37.284844Z","shell.execute_reply.started":"2025-02-12T14:37:27.106424Z","shell.execute_reply":"2025-02-12T14:37:37.284035Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# X-Ray detection model","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**By: Bernard Adhitya Kurniawan**\n\nThis is a quick demonstration on how to use a Convolutional Neural Network (CNN), specifically a pre-trained ResNet model, to analyze knee X-ray images and assess the severity of osteoarthritis using the Osteoarthritis Initiative (OAI) dataset.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Import Libraries\nFirst, we need to import the necessary libraries for data handling, model building, training, and evaluation.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models, utils\n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:37:37.285915Z","iopub.execute_input":"2025-02-12T14:37:37.286173Z","iopub.status.idle":"2025-02-12T14:38:04.197109Z","shell.execute_reply.started":"2025-02-12T14:37:37.286147Z","shell.execute_reply":"2025-02-12T14:38:04.19586Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Load and Prepare the Dataset\nWe will create the function `load_dataset_as_dataframe()` to load the OAI dataset from the subdirectories prepared for us; `train/` and `test/`, and organize the image paths and labels.\n\n- We traverse through each class folder (representing osteoarthritis severity grades; `['0', '1', '2', '3', '4']`) and collect image paths and corresponding labels.\n- The classes list contains all the class names, and class_to_idx maps these class names to numeric labels.\n- We create a DataFrame data for easier data manipulation.","metadata":{}},{"cell_type":"code","source":"def load_dataset_as_dataframe(subdir):\n    # Define the path to the dataset\n    data_dir = f'/kaggle/input/knee-osteoarthritis-dataset-with-severity/{subdir}'\n    print(f'Load dataset from `{subdir}` subdirectory')\n\n    # Create lists to store image paths and labels\n    image_paths = []\n    labels = []\n\n    # Get the list of class directories\n    classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n    classes.sort()\n    print('Classes:', classes)\n\n    # Map class names to labels\n    class_to_idx = {class_name: idx for idx, class_name in enumerate(classes)}\n\n    # Loop over each class directory\n    for class_name in classes:\n        class_dir = os.path.join(data_dir, class_name)\n        label = class_to_idx[class_name]\n        # Get all image files in the class directory\n        for img_name in os.listdir(class_dir):\n            img_path = os.path.join(class_dir, img_name)\n            if os.path.isfile(img_path):\n                image_paths.append(img_path)\n                labels.append(label)\n\n    # Create a DataFrame\n    data = pd.DataFrame({\n        'image_path': image_paths,\n        'label': labels\n    })\n    \n    # Show the distribution of labels in the dataset\n    dataset_distribution_dict = {}\n    for i in range(5):\n        dataset_distribution_dict[i] = len(data[data['label'] == i])\n    print(dataset_distribution_dict)\n    print()\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:04.19932Z","iopub.execute_input":"2025-02-12T14:38:04.199787Z","iopub.status.idle":"2025-02-12T14:38:04.207434Z","shell.execute_reply.started":"2025-02-12T14:38:04.199756Z","shell.execute_reply":"2025-02-12T14:38:04.206685Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Split the Dataset\nUsing the above function `load_dataset_as_dataframe()`, we'll load the test and train dataset as dataframe","metadata":{}},{"cell_type":"code","source":"# Prepare training and test dataset as dataframes\nclasses = ['0', '1', '2', '3', '4']\ntrain_df = load_dataset_as_dataframe('train')\ntest_df = load_dataset_as_dataframe('test')","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:04.20825Z","iopub.execute_input":"2025-02-12T14:38:04.208472Z","iopub.status.idle":"2025-02-12T14:38:15.241807Z","shell.execute_reply.started":"2025-02-12T14:38:04.208448Z","shell.execute_reply":"2025-02-12T14:38:15.240829Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Define Image Transformations\nWe define transformations for data augmentation and normalization.\n\n* Images are resized to 224x224 pixels to match the input size expected by ResNet.\n* Data augmentation is applied to the training set with random horizontal flips.\n* Images are normalized using ImageNet mean and standard deviation values.","metadata":{}},{"cell_type":"code","source":"# Define image transformations\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet standards\n                         std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:15.243354Z","iopub.execute_input":"2025-02-12T14:38:15.2437Z","iopub.status.idle":"2025-02-12T14:38:15.249166Z","shell.execute_reply.started":"2025-02-12T14:38:15.243664Z","shell.execute_reply":"2025-02-12T14:38:15.248437Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Create Custom Dataset Class\nWe create a custom dataset class to handle image loading and preprocessing.\n\n* The `KneeDataset` class inherits from torch.utils.data.Dataset.\n* The `__getitem__` method loads and returns an image and its label.","metadata":{}},{"cell_type":"code","source":"# Create custom dataset class\nclass KneeDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.loc[idx, 'image_path']\n        label = self.df.loc[idx, 'label']\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:15.250242Z","iopub.execute_input":"2025-02-12T14:38:15.250515Z","iopub.status.idle":"2025-02-12T14:38:15.256249Z","shell.execute_reply.started":"2025-02-12T14:38:15.250489Z","shell.execute_reply":"2025-02-12T14:38:15.255367Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Create DataLoaders\nWe create DataLoader objects for batching and shuffling the data.\n\n* `batch_size=32` specifies the number of samples per batch.\n* `shuffle=True` randomizes the order of data every epoch in the training set.","metadata":{}},{"cell_type":"code","source":"# Create dataset instances\ntrain_dataset = KneeDataset(train_df, transform=train_transform)\ntest_dataset = KneeDataset(test_df, transform=test_transform)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:15.257319Z","iopub.execute_input":"2025-02-12T14:38:15.257569Z","iopub.status.idle":"2025-02-12T14:38:15.262801Z","shell.execute_reply.started":"2025-02-12T14:38:15.257543Z","shell.execute_reply":"2025-02-12T14:38:15.262019Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7: Visualize Sample Images\nWe can visualize a batch of training images to verify the data loading and transformations.\n\n* We define an `imshow` function to display images after unnormalizing them.\n* We use `utils.make_grid` to create a grid of images.","metadata":{}},{"cell_type":"code","source":"# Function to display images\ndef imshow(img):\n    img = img.numpy().transpose((1, 2, 0))\n    # Unnormalize\n    mean = np.array([0.485, 0.456, 0.406])\n    std  = np.array([0.229, 0.224, 0.225])\n    img  = std * img + mean\n    img  = np.clip(img, 0, 1)\n    plt.imshow(img)\n    plt.axis('off')\n\n# Get a batch of training data\nimages, labels = next(iter(train_loader))\n\n# Make a grid from batch\nout = utils.make_grid(images)\n\n# Display images\nplt.figure(figsize=(10, 10))\nimshow(out)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:15.263945Z","iopub.execute_input":"2025-02-12T14:38:15.264287Z","iopub.status.idle":"2025-02-12T14:38:16.721014Z","shell.execute_reply.started":"2025-02-12T14:38:15.264261Z","shell.execute_reply":"2025-02-12T14:38:16.720229Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 8: Load and Modify the Pre-trained ResNet Model\nWe load a pre-trained ResNet18 model and modify the final layer to match our number of classes.\n\n* We replace the final fully connected layer (`model.fc`) to output the correct number of classes for our dataset.\n* `pretrained=True` loads weights trained on ImageNet.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\n\n# Load the model\nmodel = models.resnet18()\n\n# Load manually downloaded weights\nweights_path = \"/kaggle/input/resnet/pytorch/default/1/resnet18-f37072fd.pth\"  # Adjust path accordingly\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Modify the final layer\nnum_ftrs = model.fc.in_features\nnum_classes = len(classes)\nmodel.fc = nn.Linear(num_ftrs, num_classes)","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:16.724331Z","iopub.execute_input":"2025-02-12T14:38:16.724603Z","iopub.status.idle":"2025-02-12T14:38:17.584551Z","shell.execute_reply.started":"2025-02-12T14:38:16.724567Z","shell.execute_reply":"2025-02-12T14:38:17.583435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 9: Define Loss Function and Optimizer\nWe set up the loss function and optimizer for training.\n\n* `CrossEntropyLoss` is suitable for multi-class classification.\n* `Adam` optimizer is used with a learning rate of 0.001.","metadata":{}},{"cell_type":"code","source":"# Move model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:17.585812Z","iopub.execute_input":"2025-02-12T14:38:17.586139Z","iopub.status.idle":"2025-02-12T14:38:17.593327Z","shell.execute_reply.started":"2025-02-12T14:38:17.586106Z","shell.execute_reply":"2025-02-12T14:38:17.592349Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 10: Train the Model\nWe train the model for a few epochs.\n\n* We iterate over the training data, compute the loss, perform backpropagation, and update the model weights.\n* `model.train()` sets the model to training mode.","metadata":{}},{"cell_type":"code","source":"# Number of epochs\nnum_epochs = 25\n\n# Training loop with progress bars\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n    \n    # Wrap the train_loader with tqdm for a progress bar\n    pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n    for images, labels in pbar:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n        \n        # Update running loss\n        running_loss += loss.item() * images.size(0)\n        \n        # Calculate accuracy within the batch\n        _, preds = torch.max(outputs, 1)\n        total_correct += torch.sum(preds == labels.data)\n        total_samples += labels.size(0)\n        \n        # Update progress bar description\n        pbar.set_postfix({\n            'loss': f'{loss.item():.4f}',\n            'acc': f'{(total_correct/total_samples*100):.2f}%'\n        })\n    \n    epoch_loss = running_loss / len(train_dataset)\n    epoch_acc = total_correct.double() / len(train_dataset)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2025-02-12T14:38:17.594498Z","iopub.execute_input":"2025-02-12T14:38:17.594753Z","iopub.status.idle":"2025-02-12T15:15:17.903657Z","shell.execute_reply.started":"2025-02-12T14:38:17.594727Z","shell.execute_reply":"2025-02-12T15:15:17.902657Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 11: Evaluate the Model\nWe test the model on the test set and evaluate its performance.\n\n* `model.eval()` sets the model to evaluation mode.\n* We disable gradient computation with `torch.no_grad()`.\n* We collect all predictions and true labels to compute accuracy and generate reports.\n* The confusion matrix and classification report provide detailed insights into model performance.","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        \n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Compute accuracy\naccuracy = accuracy_score(all_labels, all_preds)\nprint(f'Accuracy on test set: {accuracy:.4f}')\n\n# Classification report\nprint('Classification Report:')\nprint(classification_report(all_labels, all_preds, target_names=classes))\n\n# Confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\nprint('Confusion Matrix:')\nprint(cm)\n\n# Plot confusion matrix\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=classes, yticklabels=classes)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-12T15:15:17.905075Z","iopub.execute_input":"2025-02-12T15:15:17.905388Z","iopub.status.idle":"2025-02-12T15:15:28.722493Z","shell.execute_reply.started":"2025-02-12T15:15:17.905357Z","shell.execute_reply":"2025-02-12T15:15:28.72164Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Saving**  ","metadata":{}},{"cell_type":"code","source":"# Define path to save the model\nsave_path = \"best_model_knee.pth\"\n\n# Save the entire model\ntorch.save(model.state_dict(), save_path)\n\nprint(f\"Model saved successfully at {save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:15:28.723793Z","iopub.execute_input":"2025-02-12T15:15:28.724099Z","iopub.status.idle":"2025-02-12T15:15:28.799303Z","shell.execute_reply.started":"2025-02-12T15:15:28.724065Z","shell.execute_reply":"2025-02-12T15:15:28.798574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NEW DATASET SAVE**","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\n# Load trained model\nmodel.load_state_dict(torch.load(\"best_model_knee.pth\", map_location=device))\nmodel.eval()\n\n# Store predictions\nxray_preds = []\nxray_filenames = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        probs = torch.nn.functional.softmax(outputs, dim=1)  # Get probability scores\n        xray_preds.extend(probs[:, 1].cpu().numpy())  # Probability of class 1\n\n# Create DataFrame for predictions\nxray_pred_df = pd.DataFrame({'Xray_pred': xray_preds})\n\n# Save predictions to CSV\nxray_pred_df.to_csv(\"Xray_predictions.csv\", index=False)\n\nprint(\"X-ray predictions saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:15:28.800324Z","iopub.execute_input":"2025-02-12T15:15:28.800704Z","iopub.status.idle":"2025-02-12T15:15:38.078012Z","shell.execute_reply.started":"2025-02-12T15:15:28.800674Z","shell.execute_reply":"2025-02-12T15:15:38.076764Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# fusion model","metadata":{}},{"cell_type":"markdown","source":"step-1","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Define file paths\nmiRNA_pred_path = \"/kaggle/working/miRNA_predictions.csv\"\nxray_pred_path = \"/kaggle/working/Xray_predictions.csv\"\nfusion_output_path = \"/kaggle/working/fusion_dataset.csv\"\n\n# Load both prediction files\nmiRNA_pred_df = pd.read_csv(miRNA_pred_path)\nxray_pred_df = pd.read_csv(xray_pred_path)\n\n# Ensure both have the same length (handling missing values if needed)\nmin_len = min(len(miRNA_pred_df), len(xray_pred_df))\nmiRNA_pred_df = miRNA_pred_df.iloc[:min_len]\nxray_pred_df = xray_pred_df.iloc[:min_len]\n\n# Combine into one DataFrame\nfusion_data = pd.concat([miRNA_pred_df, xray_pred_df], axis=1)\n\n# Add labels (assuming available)\n# Replace `y_labels` with actual labels if they exist\nfusion_data['label'] = np.random.choice([0, 1], size=len(fusion_data))  # Mock labels\n\n# Save the combined dataset\nfusion_data.to_csv(fusion_output_path, index=False)\n\nprint(f\"Fusion dataset created successfully at {fusion_output_path}!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:22:39.84855Z","iopub.execute_input":"2025-02-12T15:22:39.848923Z","iopub.status.idle":"2025-02-12T15:22:39.862654Z","shell.execute_reply.started":"2025-02-12T15:22:39.848889Z","shell.execute_reply":"2025-02-12T15:22:39.862002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"step-2","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n\n# Define file path for the fusion dataset\nfusion_data_path = \"/kaggle/working/fusion_dataset.csv\"\n\n# Load the fusion dataset\nfusion_data = pd.read_csv(fusion_data_path)\n\n# Define features and target\nX_fusion = fusion_data[['miRNA_pred', 'Xray_pred']]\ny_fusion = fusion_data['label']\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_fusion, y_fusion, test_size=0.2, random_state=42)\n\n# Train a simple Random Forest model\nfusion_model = RandomForestClassifier(n_estimators=100, random_state=42)\nfusion_model.fit(X_train, y_train)\n\n# Evaluate on test set\ny_pred = fusion_model.predict(X_test)\ny_prob = fusion_model.predict_proba(X_test)[:, 1]\n\n# Print results\nprint(\"Fusion Model Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Fusion Model AUC:\", roc_auc_score(y_test, y_prob))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n\n# ANALYTICS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:22:56.302843Z","iopub.execute_input":"2025-02-12T15:22:56.303237Z","iopub.status.idle":"2025-02-12T15:22:56.484476Z","shell.execute_reply.started":"2025-02-12T15:22:56.303202Z","shell.execute_reply":"2025-02-12T15:22:56.483687Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# COMPARE","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, classification_report\nimport pandas as pd\n\n# Define evaluation function\ndef evaluate_model(y_true, y_pred, y_prob=None, model_name=\"Model\"):\n    accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n    auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n\n    print(f\"\\n{model_name} Performance:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-score: {f1:.4f}\")\n    if auc:\n        print(f\"ROC-AUC: {auc:.4f}\")\n\n    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n\n    return accuracy, precision, recall, f1, auc\n\n# Paths to predictions stored in Kaggle's working directory\nmiRNA_pred_path = \"/kaggle/working/miRNA_predictions.csv\"\nxray_pred_path = \"/kaggle/working/Xray_predictions.csv\"\nfusion_data_path = \"/kaggle/working/fusion_dataset.csv\"\n\n# Load predictions\nmiRNA_pred_df = pd.read_csv(miRNA_pred_path)\nxray_pred_df = pd.read_csv(xray_pred_path)\nfusion_data = pd.read_csv(fusion_data_path)\n\n# Extract labels and predictions\ny_test_miRNA = fusion_data['label']\ny_pred_miRNA = miRNA_pred_df['miRNA_pred'].round().astype(int)  # Convert probabilities to binary predictions\ny_prob_miRNA = miRNA_pred_df['miRNA_pred']  # Probabilities\n\n# Ensure X-ray predictions match test samples\ny_test_xray = fusion_data['label'][:len(xray_pred_df)]\ny_pred_xray = xray_pred_df['Xray_pred'].round().astype(int)[:len(y_test_xray)]\ny_prob_xray = xray_pred_df['Xray_pred'][:len(y_test_xray)]\n\ny_test_fusion = fusion_data['label']\nfusion_model_preds = fusion_data[['miRNA_pred', 'Xray_pred']]  # Features for the fusion model\n\n# Evaluate miRNA Model\nmiRNA_accuracy, miRNA_precision, miRNA_recall, miRNA_f1, miRNA_auc = evaluate_model(\n    y_test_miRNA, y_pred_miRNA, y_prob_miRNA, \"miRNA Model\"\n)\n\n# Evaluate X-ray Model\nxray_accuracy, xray_precision, xray_recall, xray_f1, xray_auc = evaluate_model(\n    y_test_xray, y_pred_xray, y_prob_xray, \"X-ray Model\"\n)\n\n# Evaluate Fusion Model\nfusion_accuracy, fusion_precision, fusion_recall, fusion_f1, fusion_auc = evaluate_model(\n    y_test_fusion, fusion_model.predict(fusion_model_preds), fusion_model.predict_proba(fusion_model_preds)[:, 1], \"Fusion Model\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:25:10.771524Z","iopub.execute_input":"2025-02-12T15:25:10.772449Z","iopub.status.idle":"2025-02-12T15:25:10.834708Z","shell.execute_reply.started":"2025-02-12T15:25:10.772397Z","shell.execute_reply":"2025-02-12T15:25:10.83392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Create a DataFrame with performance metrics\nresults_df = pd.DataFrame({\n    \"Model\": [\"miRNA\", \"X-ray\", \"Fusion\"],\n    \"Accuracy\": [miRNA_accuracy, xray_accuracy, fusion_accuracy],\n    \"Precision\": [miRNA_precision, xray_precision, fusion_precision],\n    \"Recall\": [miRNA_recall, xray_recall, fusion_recall],\n    \"F1-score\": [miRNA_f1, xray_f1, fusion_f1],\n    \"ROC-AUC\": [miRNA_auc, xray_auc, fusion_auc]\n})\n\n# Define the output path\nresults_path = \"/kaggle/working/model_performance.csv\"\n\n# Save results to CSV\nresults_df.to_csv(results_path, index=False)\n\nprint(\"\\nPerformance Comparison Table:\")\nprint(results_df)\nprint(f\"\\nPerformance results saved to {results_path}!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:25:45.886136Z","iopub.execute_input":"2025-02-12T15:25:45.886532Z","iopub.status.idle":"2025-02-12T15:25:45.899672Z","shell.execute_reply.started":"2025-02-12T15:25:45.886495Z","shell.execute_reply":"2025-02-12T15:25:45.898794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import confusion_matrix\n\n# Define the function to plot and save confusion matrices\ndef plot_confusion_matrix(y_true, y_pred, model_name):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Progressor\", \"Progressor\"], yticklabels=[\"Non-Progressor\", \"Progressor\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(f\"Confusion Matrix - {model_name}\")\n    \n    # Save the plot\n    output_path = f\"/kaggle/working/conf_matrix_{model_name.replace(' ', '_')}.png\"\n    plt.savefig(output_path)\n    plt.show()\n    \n    print(f\"Confusion matrix saved at: {output_path}\")\n# Ensure predictions exist\ny_pred_fusion = fusion_model.predict(fusion_model_preds).round().astype(int)\n\n# Now plot confusion matrices\nplot_confusion_matrix(y_test_miRNA, y_pred_miRNA, \"miRNA Model\")\nplot_confusion_matrix(y_test_xray, y_pred_xray, \"X-ray Model\")\nplot_confusion_matrix(y_test_fusion, y_pred_fusion, \"Fusion Model\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:27:07.026812Z","iopub.execute_input":"2025-02-12T15:27:07.027194Z","iopub.status.idle":"2025-02-12T15:27:07.606754Z","shell.execute_reply.started":"2025-02-12T15:27:07.027162Z","shell.execute_reply":"2025-02-12T15:27:07.606032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Function to plot and save feature importance\ndef plot_feature_importance(model, feature_names, title=\"Feature Importance\", filename=\"feature_importance.png\"):\n\n    importances = model.feature_importances_\n    indices = np.argsort(importances)[::-1]\n    \n    plt.figure(figsize=(8, 5))\n    plt.title(title)\n    plt.barh(range(len(indices)), importances[indices], align=\"center\")\n    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n    plt.xlabel(\"Relative Importance\")\n    plt.gca().invert_yaxis()\n    \n    # Save the plot\n    output_path = f\"/kaggle/working/{filename}\"\n    plt.savefig(output_path)\n    plt.show()\n    \n    print(f\"Feature importance plot saved at: {output_path}\")\n\n# Feature Importance for miRNA Model\nplot_feature_importance(best_model, selected_features, \"Feature Importance - miRNA Model\", \"feature_importance_miRNA.png\")\n\n# Ensure fusion_model is defined before calling this\nplot_feature_importance(fusion_model, [\"miRNA_pred\", \"Xray_pred\"], \"Feature Importance - Fusion Model\", \"feature_importance_fusion.png\")\n\n\nplot_feature_importance(best_model, selected_features, \"Feature Importance - miRNA Model\", \"feature_importance_miRNA.png\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:37:44.966121Z","iopub.execute_input":"2025-02-12T15:37:44.96653Z","iopub.status.idle":"2025-02-12T15:37:45.445487Z","shell.execute_reply.started":"2025-02-12T15:37:44.966495Z","shell.execute_reply":"2025-02-12T15:37:45.444682Z"}},"outputs":[],"execution_count":null}]}